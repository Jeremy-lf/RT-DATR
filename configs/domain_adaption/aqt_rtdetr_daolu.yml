_BASE_: [
  './_base_/runtime.yml',
]

architecture: DA_RTDETR

# pretrain_weights: https://bj.bcebos.com/v1/paddledet/models/pretrained/ResNet34_vd_pretrained.pdparams
norm_type: sync_bn
pretrain_weights: rtdetr_r34vd_dec4_6x_coco.pdparams


weights: output/o2net
find_unused_parameters: True
save_dir: output/rtdetr
log_iter: 20

da_method: o2net_rtdetr

hidden_dim: 256
use_focal_loss: True

eval_size: [736, 736]

use_gpu: true
use_ema: true
ema_decay: 0.9998
ema_black_list: ['proj_conv.weight']
worker_num: 8


DA_RTDETR:
  backbone: ResNet
  neck: HybridEncoder
  transformer: DA_RTDETRTransformer
  detr_head: DA_DINOHead
  post_process: DETRPostProcess

ResNet:
  depth: 34
  variant: d
  return_idx: [1, 2, 3]
  freeze_at: -1
  freeze_norm: false
  norm_decay: 0.

HybridEncoder:
  hidden_dim: 256
  use_encoder_idx: [2]
  num_encoder_layers: 1
  encoder_layer:
    name: TransformerLayer
    d_model: 256
    nhead: 8
    dim_feedforward: 1024
    dropout: 0.
    activation: 'gelu'
  expansion: 0.5
  depth_mult: 1.0

RTDETRTransformer:
  num_queries: 300
  position_embed_type: sine
  feat_strides: [8, 16, 32]
  num_levels: 3
  nhead: 8
  num_decoder_layers: 4
  dim_feedforward: 1024
  dropout: 0.0
  activation: relu
  num_denoising: 100
  label_noise_ratio: 0.5
  box_noise_scale: 1.0
  learnt_init_query: False
  eval_idx: -1


DINOHead:
  loss:
    name: DINOLoss
    loss_coeff: {class: 1, bbox: 5, giou: 2}
    aux_loss: True
    use_vfl: True
    matcher:
      name: HungarianMatcher
      matcher_coeff: {class: 2, bbox: 5, giou: 2}

DETRPostProcess:
  num_top_queries: 300

metric: COCO
num_classes: 5
num_classes_bg: &num_classes_bg 6

# partial labeled COCO, use `SemiCOCODataSet` rather than `COCODataSet`
TrainDataset:
  !YeWuCOCODataSet
    image_dir: ''
    anno_path: train_0829.json
    dataset_dir: /root/paddlejob/workspace/env_run/lvfeng/output/road_scene_det_train_0828
    data_fields: ['image', 'gt_bbox', 'gt_class', 'is_crowd', 'gt_categories']
    class_num_bg: *num_classes_bg  # num_classes + 1 represent background
    allow_empty: true

# partial unlabeled COCO, use `SemiCOCODataSet` rather than `COCODataSet`
UnsupTrainDataset:
  !SemiCOCODataSet
    image_dir: ''
    anno_path: neimeng_unlabel_target.json
    dataset_dir: /root/paddlejob/workspace/env_run/datasets
    data_fields: ['image']
    supervised: false

EvalDataset:
  !COCODataSet
    image_dir: ''
    anno_path: test_0829.json
    dataset_dir: /root/paddlejob/workspace/env_run/lvfeng/output/road_scene_det_eval_0828
    allow_empty: true

TestDataset:
  !ImageFolder
    anno_path: "" # also support txt (like VOC's label_list.txt)
    dataset_dir: "" # if set, anno_path will be 'dataset_dir/anno_path'
  
SemiTrainReader:
  sample_transforms:
    - Decode: {}
    - RandomDistort: {prob: 0.8}
    - RandomExpand: {fill_value: [0., 0., 0.]}
    - RandomCrop: {prob: 0.8}
    - RandomFlip: {}
  weak_aug:
    - RandomFlip: {prob: 0.0}
  strong_aug:
    - StrongAugImage: {transforms: [
        RandomColorJitter: {prob: 0.8, brightness: 0.4, contrast: 0.4, saturation: 0.4, hue: 0.1},
        RandomErasingCrop: {},
        RandomGaussianBlur: {prob: 0.5, sigma: [0.1, 2.0]},
        RandomGrayscale: {prob: 0.2},
      ]}
  sup_batch_transforms:
    - BatchRandomResizeForSSOD: {target_size: [608, 640, 640, 640, 672, 704, 736, 768, 800], random_size: True, random_interp: True, keep_ratio: False}
    - NormalizeImage: {mean: [0., 0., 0.], std: [1., 1., 1.], norm_type: none}
    - NormalizeBox: {}
    - BboxXYXY2XYWH: {}
    - Permute: {}
  unsup_batch_transforms:
    - BatchRandomResizeForSSOD: {target_size: [608, 640, 640, 640, 672, 704, 736, 768, 800], random_size: True, random_interp: True, keep_ratio: False}
    - NormalizeImage: {mean: [0., 0., 0.], std: [1., 1., 1.], norm_type: none}
    - NormalizeBox: {}
    - BboxXYXY2XYWH: {}
    - Permute: {}
  sup_batch_size: 8
  unsup_batch_size: 8
  shuffle: true
  drop_last: true
  collate_batch: false
  use_shared_memory: false
  sup_cls_aware: true
  cls_ids: [1, 2, 3, 4, 5, 6] # num_classes + 1 represent background
  cls_prob: [0.25, 0.15, 0.05, 0.25, 0.05, 0.25]  # probability of class

EvalReader:
  sample_transforms:
    - Decode: {}
    - Resize: {target_size: [736, 736], keep_ratio: False}
    - NormalizeImage: {mean: [0., 0., 0.], std: [1., 1., 1.], norm_type: none}
    - Permute: {}
  batch_size: 1
  shuffle: false
  drop_last: false


TestReader:
  sample_transforms:
    - Decode: {}
    - Resize: { target_size: [736, 736], keep_ratio: False }
    - NormalizeImage: {mean: [0., 0., 0.], std: [1., 1., 1.], norm_type: none}
    - Permute: {}
  batch_size: 1
  shuffle: false
  drop_last: false


epoch: 120

LearningRate:
  base_lr: 0.0002
  schedulers:
  - !PiecewiseDecay
    gamma: 1.0
    milestones: [140]
    use_warmup: false
  - !LinearWarmup
    start_factor: 0.001
    steps: 200

# epoch: 100
# LearningRate:
#   base_lr: 0.0002
#   schedulers:
#   - !CosineDecay
#     max_epochs: 120 #180
#     use_warmup: True
#   - !LinearWarmup
#     start_factor: 0.
#     epochs: 2

OptimizerBuilder:
  clip_grad_by_norm: 0.1
  regularizer: false
  optimizer:
    type: AdamW
    weight_decay: 0.0001