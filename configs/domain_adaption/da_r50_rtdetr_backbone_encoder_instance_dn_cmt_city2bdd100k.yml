_BASE_: [
  './_base_/runtime.yml',
]

architecture: DA_RTDETR_Backbone_Encoder_Instance

# pretrain_weights: https://bj.bcebos.com/v1/paddledet/models/pretrained/ResNet34_vd_pretrained.pdparams
pretrain_weights: output/rtdetr_r50vd_6x_coco_cityscapes2bdd100k/best_model.pdparams
norm_type: sync_bn

save_dir: output/cityscapes2bdd100k

use_ema: True
ema_decay: 0.9999
ema_decay_type: "exponential"
ema_filter_no_grad: True

weights: output/
find_unused_parameters: True
log_iter: 50

da_method: rtdetr_backbone_encoder_instance_dn_cmt

hidden_dim: 256
use_focal_loss: True

eval_size: [640, 640]

use_gpu: true
worker_num: 8

metric: COCO
num_classes: 8
classwise: true


DA_RTDETR_Backbone_Encoder_Instance:
  backbone: ResNet
  neck: HybridEncoder_Backbone
  transformer: DA_RTDETRTransformer_Global_Instance
  detr_head: DA_DINOHead_Econder_Instance
  post_process: DETRPostProcess

ResNet:
  # index 0 stands for res2
  depth: 50
  variant: d
  norm_type: bn
  freeze_at: 0
  return_idx: [1, 2, 3]
  lr_mult_list: [0.1, 0.1, 0.1, 0.1]
  num_stages: 4
  freeze_stem_only: True

HybridEncoder_Backbone:
  hidden_dim: 256
  use_encoder_idx: [2]
  num_encoder_layers: 1
  encoder_layer:
    name: TransformerLayer
    d_model: 256
    nhead: 8
    dim_feedforward: 1024
    dropout: 0.
    activation: 'gelu'
  expansion: 1.0


DA_RTDETRTransformer_Global_Instance:
  num_queries: 300
  position_embed_type: sine
  feat_strides: [8, 16, 32]
  num_levels: 3
  nhead: 8
  num_decoder_layers: 6
  dim_feedforward: 1024
  dropout: 0.0
  activation: relu
  num_denoising: 100
  label_noise_ratio: 0.5
  box_noise_scale: 1.0
  learnt_init_query: False

DA_DINOHead_Econder_Instance:
  loss:
    name: DINOLoss
    loss_coeff: {class: 1, bbox: 5, giou: 2}
    aux_loss: True
    use_vfl: True
    matcher:
      name: HungarianMatcher
      matcher_coeff: {class: 2, bbox: 5, giou: 2}

DETRPostProcess:
  num_top_queries: 300


SemiTrainReader:
  sample_transforms:
    - Decode: {}
    - RandomDistort: {prob: 0.8}
    - RandomExpand: {fill_value: [123.675, 116.28, 103.53]}
    - RandomCrop: {prob: 0.8}
    - RandomFlip: {}
    - RandomColorJitter: {prob: 0.8, brightness: 0.4, contrast: 0.4, saturation: 0.4, hue: 0.1}
    - RandomErasingCrop: {}
    - RandomGaussianBlur: {prob: 0.5, sigma: [0.1, 2.0]}
    - RandomGrayscale: {prob: 0.2}
  # weak_aug:
  #   - RandomFlip: {prob: 0.0}
  # strong_aug:
  #   - StrongAugImage: {transforms: [
  #       RandomColorJitter: {prob: 0.8, brightness: 0.4, contrast: 0.4, saturation: 0.4, hue: 0.1},
  #       RandomErasingCrop: {},
  #       RandomGaussianBlur: {prob: 0.5, sigma: [0.1, 2.0]},
  #       RandomGrayscale: {prob: 0.2},
  #     ]}
  sup_batch_transforms:
    - BatchRandomResize: {target_size: [480, 512, 544, 576, 608, 640, 640, 640, 672, 704, 736, 768, 800], random_size: True, random_interp: True, keep_ratio: False}
    - NormalizeImage: {mean: [0., 0., 0.], std: [1., 1., 1.], norm_type: none}
    - NormalizeBox: {}
    - BboxXYXY2XYWH: {}
    - Permute: {}
  unsup_batch_transforms:
    - BatchRandomResize: {target_size: [480, 512, 544, 576, 608, 640, 640, 640, 672, 704, 736, 768, 800], random_size: True, random_interp: True, keep_ratio: False}
    - NormalizeImage: {mean: [0., 0., 0.], std: [1., 1., 1.], norm_type: none}
    - NormalizeBox: {}
    - BboxXYXY2XYWH: {}
    - Permute: {}
  sup_batch_size: 2
  unsup_batch_size: 2
  shuffle: true
  drop_last: true
  collate_batch: false
  use_shared_memory: false

EvalReader:
  sample_transforms:
    - Decode: {}
    - Resize: {target_size: [640, 640], keep_ratio: False, interp: 2}
    - NormalizeImage: {mean: [0., 0., 0.], std: [1., 1., 1.], norm_type: none}
    - Permute: {}
  batch_size: 8
  shuffle: false
  drop_last: false


TestReader:
  inputs_def:
    image_shape: [3, 640, 640]
  sample_transforms:
    - Decode: {}
    - Resize: {target_size: [640, 640], keep_ratio: False, interp: 2}
    - NormalizeImage: {mean: [0., 0., 0.], std: [1., 1., 1.], norm_type: none}
    - Permute: {}
  batch_size: 1
  shuffle: false
  drop_last: false




# partial labeled COCO, use `SemiCOCODataSet` rather than `COCODataSet`
TrainDataset:
  !SemiCOCODataSet
    image_dir: leftImg8bit/train
    anno_path: label/cityscapes_train.json
    dataset_dir: data/cityscapes
    data_fields: ['image', 'gt_bbox', 'gt_class', 'is_crowd']

# partial unlabeled COCO, use `SemiCOCODataSet` rather than `COCODataSet`
UnsupTrainDataset:
  !SemiCOCODataSet
    image_dir: images/100k/train
    anno_path: annotations/bdd_daytime_train.json
    dataset_dir: data/bdd100k
    data_fields: ['image']
    supervised: False

EvalDataset:
  !COCODataSet
    image_dir: images/100k/val
    anno_path: annotations/bdd_daytime_val.json
    dataset_dir: data/bdd100k

# # FoggyCityScapes
# UnsupTrainDataset:
#   !SemiCOCODataSet
#     image_dir: leftImg8bit_foggy/train
#     anno_path: label/foggy_cityscapes_train.json
#     dataset_dir: data/cityscapes
#     data_fields: ['image']
#     supervised: False

# FoggyCityscapes
# EvalDataset:
#   !COCODataSet
#     image_dir: leftImg8bit_foggy/val
#     anno_path:  label/foggy_cityscapes_val.json
#     dataset_dir: data/cityscapes


TestDataset:
  !ImageFolder
    anno_path: "" # also support txt (like VOC's label_list.txt)
    dataset_dir: "" # if set, anno_path will be 'dataset_dir/anno_path'


epoch: 72

LearningRate:
  base_lr: 0.0002
  schedulers:
  - !PiecewiseDecay
    gamma: 1.0
    milestones: [100]
    use_warmup: true
  - !LinearWarmup
    start_factor: 0.001
    steps: 200


OptimizerBuilder:
  clip_grad_by_norm: 0.1
  regularizer: false
  optimizer:
    type: AdamW
    weight_decay: 0.0001
